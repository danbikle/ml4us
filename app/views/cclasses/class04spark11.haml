%h2 Class04 Answer:
%h2  Work through the first page of the Spark Quick-Start:

%p
  I found the Spark Tutorial at the URL listed below:
%p
  %a(href='http://spark.apache.org/docs/latest/quick-start.html' target='x')
    http://spark.apache.org/docs/latest/quick-start.html

%p I tried shell and Scala commands listed below:
.syntax
  %pre
    %code.bash
      cd ~/spark
      bin/spark-shell
      val textFile = sc.textFile("README.md")
      textFile.count()
      textFile.first()
      val linesWithSpark = textFile.filter(line => line.contains("Spark"))
      textFile.filter(line => line.contains("Spark")).count()
      textFile.map(line => line.split(" ").size).reduce((a, b) => if (a > b) a else b)
      import java.lang.Math
      textFile.map(line => line.split(" ").size).reduce((a, b) => Math.max(a, b))
      val wordCounts = textFile.flatMap(line => line.split(" ")).groupByKey(identity).count()
      wordCounts.collect()
      linesWithSpark.cache()
      linesWithSpark.count()
      linesWithSpark.count()

%p I saw some output:
.syntax
  %pre
    =render 'class04spark12'

%p I thought the logging output was too verbose; I made it less so.

%p I control the logging level by creating a file here:
.syntax
  %pre
    %code.bash ~/spark/conf/log4j.properties

%p I created the file from this file:
.syntax
  %pre
    %code.bash ~/spark/conf/log4j.properties.template

%p Now the file looks like this:
.syntax
  %pre
    =render 'class04spark14'
%p When I start spark-shell, the output is much cleaner:

.syntax
  %pre
    =render 'class04spark15'

%p After fixing the log-level, I created a folder:

.syntax
  %pre
    %code.bash mkdir ~/spark10
%p Then I created a file named ~/spark10/simple.sbt:

.syntax
  %pre
    %code.bash
      name := "Simple Project"
      version := "1.0"
      scalaVersion := "2.11.7"
      libraryDependencies += "org.apache.spark" %% "spark-core" % "2.1.1"

%p Then I created a file named ~/spark10/src/main/scala/SimpleApp.scala
.syntax
  %pre
    =render 'class04spark16'

%p The quick-start shows that I need a utility named 'sbt'.

%p But the quick-start fails to describe what sbt is or how to install it.

%p After 10 minutes with Google I learned that I use sbt to compile scala scripts.

%p Also I found a page which describes how to quickly install sbt:
%p
  %a(href='http://www.scala-sbt.org/0.13/docs/Manual-Installation.html' target='x')
    http://www.scala-sbt.org/0.13/docs/Manual-Installation.html

%p Next, I created a shell script in ~/bin/sbt

.syntax
  %pre
    =render 'class04spark17'

%p I ran these shell commands:

.syntax
  %pre
    %code.bash chmod u+x ~/bin/sbt
    echo 'export PATH=${HOME}/bin:$PATH' >> ~/.bashrc
    bash
%p Then, I used wget to get a jar file from the web:

.syntax
  %pre
    %code.bash
      cd ~/bin/
      rm -f sbt-launch.jar
      wget https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.12/sbt-launch.jar

%p Those three steps installed sbt for me.

%p Next, I ran simple shell commands:

.syntax
  %pre
    %code.bash
      cd ~/spark10/
      sbt package

%p I saw this:

.syntax
  %pre.sbarv300
    =render 'class04spark18'

%p Next, I ran simple shell commands:

.syntax
  %pre
    %code.bash
      ls -la
      ls -la target/
      ls -la target/scala-2.11/
      \~/spark/bin/spark-submit --class "SimpleApp" --master local[4] target/scala-2.11/simple-project_2.11-1.0.jar

%p I saw this:

.syntax
  %pre
    =render 'class04spark19'

%p That seemed to go well so I tried the next example listed in the quick-start:

.syntax
  %pre
    %code.bash
      dan@pavlap:~ $ cd ~/spark/
      dan@pavlap:~/spark $ 
      dan@pavlap:~/spark $ bin/run-example SparkPi
      Pi is roughly 3.138635693178466
      dan@pavlap:~/spark $ 
      dan@pavlap:~/spark $ 
      dan@pavlap:~/spark $ 
      
%p That seemed to go well so I tried the next example listed in the quick-start:

.syntax
  %pre
    %code.bash
      dan@pavlap:~/spark $ 
      dan@pavlap:~/spark $ 
      dan@pavlap:~/spark $ bin/spark-submit examples/src/main/python/pi.py
      Pi is roughly 3.146920
      dan@pavlap:~/spark $ 
      dan@pavlap:~/spark $ 

%p That seemed to go well so I tried the next example listed in the quick-start:

.syntax
  %pre
    =render 'class04spark20'

%p That seemed to go well so I was happy. That was the last example in the quick-start.

%p
  %a(href='class04#spark')
    Class04 Lab
